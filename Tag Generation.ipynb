{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In this notebook, we attempted to make a step further from the LDA mallet model results. As the LDA Mallet model only provides the topic keywords instead of the specific topic itself, we aimed to extract that topic, or concept, from the list of topic keywords. <br><br>\n",
    "  As each word has multiple meanings, we believe that for words under a particular concept, the meanings of the words are similar to each other. We used the WordNet module to obtain the meanings as Synsets, and the similarity is computed with Wu-Palmer Similarity Score<br>\n",
    "  Therefore, we took the following steps to achieve our goal: <ol>\n",
    "    <li>Compute the pairwise synset similarity for all sysnet pairs of different pair of words</li>\n",
    "    <li>Set a threshold for the similarity score for filtering</li>\n",
    "    <li>Generate a network for the remaining synsets, identify and filter components to obtain the main components</li>\n",
    "    <li>For each component, compute the similarity scores between a synset with every of its hypernyms and use the median score.</li> \n",
    "    <li>Use the median score to build a weighted hypernym-synset tree <br>\n",
    "        For each node, the weight is equal to the sum of its score and all its children's scores </li>\n",
    "    <li>Select the appropriate hypernyms based on the the score, where the score must be between the 15th and 30th percentile of scores, to have a good extent of generality and specificity.</li>\n",
    "    <li>Extract the nouns from the preprocessed selected hypernyms' definitions as Concepts/Topics</li>\n",
    "    </ol>\n",
    "  After testing on some of the topic keywords generated from the LDA model, we found that the resultant concepts from the approach is still not accurate with a lot of noise. Due to the time constraint, we did not go further and explore more approaches. However, we found out a paper that may be suitable for our case and we may test it out in the future: \n",
    "  http://www.wangzhongyuan.com/tutorial/ACL2016/Understanding-Short-Texts/Slides/Understanding-Short-Texts-Part-II-Explicit-Representation.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T06:17:19.872862Z",
     "start_time": "2020-07-29T06:17:18.023845Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "from itertools import combinations,product\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step by Step ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T06:53:15.844265Z",
     "start_time": "2020-07-29T06:53:15.836267Z"
    }
   },
   "outputs": [],
   "source": [
    "# example topic keywords\n",
    "topic = ['war','kill','conflict','refugee','military','soldier','weapon','Afghanistan','attack','peace']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T06:53:18.140343Z",
     "start_time": "2020-07-29T06:53:17.692814Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1.Compute the pairwise synset similarity for all sysnet pairs of different pair of words\n",
    "\n",
    "synset_pair = [] # [(s1,s2,w1,w2,score)]\n",
    "scores = []\n",
    "for w1,w2 in combinations(topic,r=2):\n",
    "    sw1 = wn.synsets(w1)\n",
    "    sw2 = wn.synsets(w2)\n",
    "    \n",
    "    for s1, s2 in product(sw1,sw2):\n",
    "        score = wn.wup_similarity(s1,s2)\n",
    "        if not score:\n",
    "            continue\n",
    "        if (s1,s2,w1,w2,score) in synset_pair or (s2,s1,w1,w2,score) in synset_pair:\n",
    "            continue\n",
    "        synset_pair.append((s1,s2,w1,w2,score))\n",
    "        scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T06:53:20.887130Z",
     "start_time": "2020-07-29T06:53:20.876135Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2.Set a threshold for the similarity score for filtering\n",
    "# We use three possible ways to filter out the synset:\n",
    "#    1. A arbitrary number of 30 as the maximum number of sysnets to be included\n",
    "#    2. Use the 90th percentile of the similarity score as the cut-off\n",
    "#    3. Use the fix value of 0.5 for the similarity score as the cut-off\n",
    "# We use the the way that gives the min number of synsets\n",
    "# E.g. the number is 10, then Obtain the 10th highest similarity score and use that as the cut-off\n",
    "\n",
    "scores = np.array(scores)\n",
    "\n",
    "max_sysnet_num = 30\n",
    "NinetyPercentile_num = len(scores[scores>np.percentile(scores,90)])\n",
    "halfScore_num = len(scores[scores>0.5])\n",
    "\n",
    "min_synset_num = min(NinetyPercentile_num,halfScore_num,max_sysnet_num)\n",
    "   \n",
    "synset_pair_sorted = sorted(synset_pair,key=lambda x:x[-1], reverse=True)\n",
    "threshold = synset_pair_sorted[min_synset_num][-1]\n",
    "synset_pair_selected = [v for v in synset_pair_sorted if v[-1] >= threshold if v[0] != v[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T06:53:21.936847Z",
     "start_time": "2020-07-29T06:53:21.912848Z"
    }
   },
   "outputs": [],
   "source": [
    "# 3. Generate a network for the remaining synsets and identify and filter components to obtain the main components\n",
    "# The way to filter the component is through a threshold similar to step 2 \n",
    "#     where we use the 3rd largest component size as the cut-off \n",
    "nodes = set([w[0] for w in synset_pair_selected] + [w[1] for w in synset_pair_selected] )\n",
    "weighted_edge_list = {\n",
    "    (w[0],w[1]):{'score':w[-1],'words':(w[2],w[3])} for w in synset_pair_selected\n",
    "}\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "G.add_nodes_from(nodes)\n",
    "G.add_edges_from(weighted_edge_list)\n",
    "nx.set_edge_attributes(G, weighted_edge_list)\n",
    "\n",
    "\n",
    "components = list(nx.connected_components(G))\n",
    "if len(components) > 3:\n",
    "    component_size = sorted(list(set([len(c) for c in components])),reverse=True)\n",
    "    try:\n",
    "        size_threshold = component_size[2]\n",
    "    except:\n",
    "        size_threshold = component_size[-1]\n",
    "\n",
    "    main_components = [c for c in components if len(c) >= size_threshold]\n",
    "else:\n",
    "    main_components = components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T06:53:22.939522Z",
     "start_time": "2020-07-29T06:53:22.924527Z"
    }
   },
   "outputs": [],
   "source": [
    "# 4. For each component, compute the similarity scores between a synset with every of its hypernyms and use the median score.\n",
    "import statistics\n",
    "def generate_hypernym_median_dict(above_threshold_synsets):\n",
    "    '''\n",
    "    @param above_threshold_synsets: list, a list of synsets \n",
    "    @return hypernym_median_dict: dict, a dictionary with synset/hypernym as keys, and the median score as values\n",
    "    \n",
    "    Description: The function will compute the similarity score between a synset or a hypernym with all its hypernyms, and use \n",
    "    the median score as the final score for that particular synset/hypernym\n",
    "    '''\n",
    "    \n",
    "    hypernym_dict = {}\n",
    "    for s in above_threshold_synsets:\n",
    "        for p in s.hypernym_paths():\n",
    "            for hypernym in p:\n",
    "                hypernym_dict[hypernym] = 1 \n",
    "                    \n",
    "    # score dict - for each hypernym in the tree, find the similarity scores with all synsets\n",
    "    hypernym_score_dict = {}\n",
    "    curr_hyp = None\n",
    "    for hypernym, syn in product(hypernym_dict.keys(),above_threshold_synsets):\n",
    "        score = wn.wup_similarity(hypernym,syn)\n",
    "        if score == None:\n",
    "            continue\n",
    "        try:\n",
    "            hypernym_score_dict[hypernym].append(score)\n",
    "        except:\n",
    "            hypernym_score_dict[hypernym] = [score]\n",
    "    \n",
    "    hypernym_median_dict = {k:statistics.median(v) for k,v in hypernym_score_dict.items()} # take the median score\n",
    "    \n",
    "    return hypernym_median_dict\n",
    "\n",
    "# 5. Use the median score to build a weighted hypernym-synset tree\n",
    "def generate_weighted_hypernym_tree(synsets,synset_score_dict):\n",
    "    '''\n",
    "    @param synsets: list\n",
    "    @synset_score_dict: dictionary\n",
    "    \n",
    "    @return tree: dictionary, the key-value pair is parent-children where the parent is the direct hypernym to all the children\n",
    "    @return synset_weights, the weight of each synset/hypernym \n",
    "    \n",
    "    Description: the function will use the synset and synset_score_dict given to construct a tree with the weights. The tree is\n",
    "    in the form of a dictionary with keys being the parent node and value being the list of the children nodes. The weight of \n",
    "    each node is calculated as the sum of its score and all its children's scores \n",
    "    '''\n",
    "    tree= {}\n",
    "    synset_weights = synset_score_dict.copy()\n",
    "    for syn in synsets:\n",
    "        for p in syn.hypernym_paths():\n",
    "            for i in range(-2,-len(p)-1,-1): # the last one is the synset itself\n",
    "                score = synset_weights[p[i+1]]\n",
    "                \n",
    "                if p[i] in synset_weights:\n",
    "                    synset_weights[p[i]] += score\n",
    "                else:\n",
    "                    synset_weights[p[i]] = score\n",
    "                \n",
    "                if p[i] in tree:\n",
    "                    if p[i+1] not in tree[p[i]]:\n",
    "                        tree[p[i]].append(p[i+1])\n",
    "                else:\n",
    "                    tree[p[i]] = [(p[i+1])]\n",
    "    \n",
    "    return tree,synset_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T06:17:39.067770Z",
     "start_time": "2020-07-29T06:17:37.196238Z"
    }
   },
   "outputs": [],
   "source": [
    "# Help function for Step 7: Extract the nouns from the preprocessed selected hypernyms' definitions as Concepts/Topics\n",
    "import spacy\n",
    "from functions.convert_to_nouns import convert\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def get_convert_tag(tag):\n",
    "    if \"NN\" in tag[:2] == 'NN':\n",
    "        return 'n'\n",
    "    elif  tag[:2] == 'JJ':\n",
    "        return 'a'\n",
    "    elif  tag[:2] == 'VB':\n",
    "        return 'v'\n",
    "    elif tag[:2] == 'RB':\n",
    "        return 'r'\n",
    "    return ''\n",
    "def extract_concept_noun_phrases(definition):\n",
    "    doc = nlp(definition)\n",
    "    result = []\n",
    "    for noun_phrase in list(doc.noun_chunks):\n",
    "        noun_phrase.merge(noun_phrase.root.tag_, noun_phrase.root.lemma_, noun_phrase.root.ent_type_)\n",
    "        if noun_phrase.root.tag_ == \"NN\":\n",
    "            noun_doc = nlp(noun_phrase.text)\n",
    "            for t in noun_doc:\n",
    "                if not t.is_stop:\n",
    "                    if 'NN' in t.tag_:\n",
    "                        result.append(t.lemma_)\n",
    "                    else:\n",
    "                        from_tag = get_convert_tag(t.tag_)\n",
    "                        if from_tag != '':\n",
    "                            result.append(convert(t.lemma_,from_tag,'n'))\n",
    "    if result:\n",
    "        return result\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T06:53:34.263035Z",
     "start_time": "2020-07-29T06:53:29.255623Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "concepts= {} # topic:[concepts]\n",
    "for i,comp in enumerate(main_components):\n",
    "    topic_concept = set()\n",
    "    \n",
    "    hypernym_median_dict = generate_hypernym_median_dict(comp)\n",
    "    tree,synset_weights = generate_weighted_hypernym_tree(comp,hypernym_median_dict)\n",
    "    \n",
    "    # 6. Select the appropriate hypernyms based on the the score\n",
    "    ceiling_threshold = np.percentile(list(synset_weights.values()),30)\n",
    "    floor_threshold = np.percentile(list(synset_weights.values()),15)\n",
    "    \n",
    "    synset_weights_selected = [(k,v) for k,v in synset_weights.items() if v <= ceiling_threshold and v>=floor_threshold]\n",
    "    \n",
    "    # 7. Extract the nouns from the preprocessed selected hypernyms' definitions as Concepts/Topics\n",
    "    definitions = [k.definition() for k,v in synset_weights_selected]\n",
    "    def_tokens = [extract_concept_noun_phrases(d) for d in definitions]\n",
    "    \n",
    "    for ts in def_tokens:\n",
    "        try:\n",
    "            topic_concept = topic_concept | set(ts) \n",
    "        except:\n",
    "            print(definitions)\n",
    "            print(def_tokens)\n",
    "            print(ts)\n",
    "    concepts[i] = list(topic_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T06:58:25.760833Z",
     "start_time": "2020-07-29T06:58:25.746935Z"
    }
   },
   "outputs": [],
   "source": [
    "concepts[2] = concepts[2][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T06:58:30.899795Z",
     "start_time": "2020-07-29T06:58:30.868795Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>concept 0</th>\n",
       "      <td>hostility</td>\n",
       "      <td>offensive</td>\n",
       "      <td>activeness</td>\n",
       "      <td>struggle</td>\n",
       "      <td>sport</td>\n",
       "      <td>game</td>\n",
       "      <td>war</td>\n",
       "      <td>armed</td>\n",
       "      <td>course</td>\n",
       "      <td>waging</td>\n",
       "      <td>conflict</td>\n",
       "      <td>military</td>\n",
       "      <td>persuader</td>\n",
       "      <td>enemy</td>\n",
       "      <td>disagreement</td>\n",
       "      <td>argument</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concept 1</th>\n",
       "      <td>opposition</td>\n",
       "      <td>state</td>\n",
       "      <td>absence</td>\n",
       "      <td>war</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concept 2</th>\n",
       "      <td>destruction</td>\n",
       "      <td>missile</td>\n",
       "      <td>ship</td>\n",
       "      <td>plane</td>\n",
       "      <td>enemy</td>\n",
       "      <td>life</td>\n",
       "      <td>tank</td>\n",
       "      <td>act</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0          1           2         3      4     5     6   \\\n",
       "concept 0    hostility  offensive  activeness  struggle  sport  game   war   \n",
       "concept 1   opposition      state     absence       war                      \n",
       "concept 2  destruction    missile        ship     plane  enemy  life  tank   \n",
       "\n",
       "              7       8       9         10        11         12     13  \\\n",
       "concept 0  armed  course  waging  conflict  military  persuader  enemy   \n",
       "concept 1                                                                \n",
       "concept 2    act                                                         \n",
       "\n",
       "                     14        15  \n",
       "concept 0  disagreement  argument  \n",
       "concept 1                          \n",
       "concept 2                          "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.DataFrame.from_dict(concepts).T\n",
    "temp.index = ['concept {}'.format(i) for i in temp.index]\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a function and Run it on all topic keywords ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T06:17:45.309223Z",
     "start_time": "2020-07-29T06:17:45.258704Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_topic(keywords):\n",
    "    synset_pair = []\n",
    "    scores = []\n",
    "    for w1,w2 in combinations(keywords,r=2):\n",
    "        sw1 = wn.synsets(w1)\n",
    "        sw2 = wn.synsets(w2)\n",
    "\n",
    "        for s1, s2 in product(sw1,sw2):\n",
    "            score = wn.wup_similarity(s1,s2)\n",
    "            if not score:\n",
    "                continue\n",
    "            if (s1,s2,w1,w2,score) in synset_pair or (s2,s1,w1,w2,score) in synset_pair:\n",
    "                continue\n",
    "            synset_pair.append((s1,s2,w1,w2,score))\n",
    "            scores.append(score)\n",
    "            \n",
    "    scores = np.array(scores)\n",
    "\n",
    "    max_sysnet_num = 30\n",
    "    NinetyPercentile_num = len(scores[scores>np.percentile(scores,90)])\n",
    "    halfScore_num = len(scores[scores>0.5])\n",
    "\n",
    "    min_synset_num = min(NinetyPercentile_num,halfScore_num,max_sysnet_num)\n",
    "\n",
    "    synset_pair_sorted = sorted(synset_pair,key=lambda x:x[-1], reverse=True)\n",
    "    threshold = synset_pair_sorted[min_synset_num][-1]\n",
    "    synset_pair_selected = [v for v in synset_pair_sorted if v[-1] >= threshold if v[0] != v[1]]\n",
    "    \n",
    "    nodes = set([w[0] for w in synset_pair_selected] + [w[1] for w in synset_pair_selected] )\n",
    "    weighted_edge_list = {\n",
    "        (w[0],w[1]):{'score':w[-1],'words':(w[2],w[3])} for w in synset_pair_selected\n",
    "    }\n",
    "\n",
    "    G = nx.Graph()\n",
    "\n",
    "    G.add_nodes_from(nodes)\n",
    "    G.add_edges_from(weighted_edge_list)\n",
    "    nx.set_edge_attributes(G, weighted_edge_list)\n",
    "\n",
    "\n",
    "    components = list(nx.connected_components(G))\n",
    "    if len(components) > 3:\n",
    "        component_size = sorted(list(set([len(c) for c in components])),reverse=True)\n",
    "        try:\n",
    "            size_threshold = component_size[2]\n",
    "        except:\n",
    "            size_threshold = component_size[-1]\n",
    "        main_components = [c for c in components if len(c) >= size_threshold]\n",
    "    else:\n",
    "        main_components = components\n",
    "        \n",
    "    concepts= {} # topic:[concepts]\n",
    "    for i,comp in enumerate(main_components):\n",
    "        topic_concept = set()\n",
    "\n",
    "        hypernym_median_dict = generate_hypernym_median_dict(comp)\n",
    "        tree,synset_weights = generate_weighted_hypernym_tree(comp,hypernym_median_dict)\n",
    "\n",
    "        # 6. Select the appropriate hypernyms based on the the score\n",
    "        ceiling_threshold = np.percentile(list(synset_weights.values()),30)\n",
    "        floor_threshold = np.percentile(list(synset_weights.values()),15)\n",
    "\n",
    "        synset_weights_selected = [(k,v) for k,v in synset_weights.items() if v <= ceiling_threshold and v>=floor_threshold]\n",
    "\n",
    "        # 7. Extract the nouns from the preprocessed selected hypernyms' definitions as Concepts/Topics\n",
    "        definitions = [k.definition() for k,v in synset_weights_selected]\n",
    "        def_tokens = [extract_concept_noun_phrases(d) for d in definitions]\n",
    "\n",
    "        for ts in def_tokens:\n",
    "            try:\n",
    "                topic_concept = topic_concept | set(ts) \n",
    "            except:\n",
    "                print(definitions)\n",
    "                print(def_tokens)\n",
    "                print(ts)\n",
    "        concepts[i] = list(topic_concept)\n",
    "    return concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T06:17:48.678190Z",
     "start_time": "2020-07-29T06:17:48.655190Z"
    }
   },
   "outputs": [],
   "source": [
    "topicWordsMatrix = pd.read_csv('data/output/topicWordMatrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T06:17:50.075879Z",
     "start_time": "2020-07-29T06:17:49.997837Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>war</td>\n",
       "      <td>woman</td>\n",
       "      <td>patient</td>\n",
       "      <td>country</td>\n",
       "      <td>kind</td>\n",
       "      <td>work</td>\n",
       "      <td>datum</td>\n",
       "      <td>school</td>\n",
       "      <td>water</td>\n",
       "      <td>money</td>\n",
       "      <td>...</td>\n",
       "      <td>feel</td>\n",
       "      <td>brain</td>\n",
       "      <td>science</td>\n",
       "      <td>planet</td>\n",
       "      <td>ocean</td>\n",
       "      <td>city</td>\n",
       "      <td>art</td>\n",
       "      <td>government</td>\n",
       "      <td>cell</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kill</td>\n",
       "      <td>man</td>\n",
       "      <td>cancer</td>\n",
       "      <td>world</td>\n",
       "      <td>structure</td>\n",
       "      <td>time</td>\n",
       "      <td>information</td>\n",
       "      <td>kid</td>\n",
       "      <td>energy</td>\n",
       "      <td>company</td>\n",
       "      <td>...</td>\n",
       "      <td>people</td>\n",
       "      <td>neuron</td>\n",
       "      <td>people</td>\n",
       "      <td>universe</td>\n",
       "      <td>fish</td>\n",
       "      <td>building</td>\n",
       "      <td>image</td>\n",
       "      <td>country</td>\n",
       "      <td>dna</td>\n",
       "      <td>people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>conflict</td>\n",
       "      <td>girl</td>\n",
       "      <td>disease</td>\n",
       "      <td>change</td>\n",
       "      <td>form</td>\n",
       "      <td>people</td>\n",
       "      <td>internet</td>\n",
       "      <td>student</td>\n",
       "      <td>oil</td>\n",
       "      <td>business</td>\n",
       "      <td>...</td>\n",
       "      <td>experience</td>\n",
       "      <td>memory</td>\n",
       "      <td>question</td>\n",
       "      <td>space</td>\n",
       "      <td>water</td>\n",
       "      <td>design</td>\n",
       "      <td>work</td>\n",
       "      <td>power</td>\n",
       "      <td>gene</td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>refugee</td>\n",
       "      <td>sex</td>\n",
       "      <td>health</td>\n",
       "      <td>China</td>\n",
       "      <td>system</td>\n",
       "      <td>change</td>\n",
       "      <td>people</td>\n",
       "      <td>child</td>\n",
       "      <td>carbon</td>\n",
       "      <td>market</td>\n",
       "      <td>...</td>\n",
       "      <td>life</td>\n",
       "      <td>consciousness</td>\n",
       "      <td>study</td>\n",
       "      <td>star</td>\n",
       "      <td>sea</td>\n",
       "      <td>build</td>\n",
       "      <td>create</td>\n",
       "      <td>political</td>\n",
       "      <td>body</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>military</td>\n",
       "      <td>boy</td>\n",
       "      <td>doctor</td>\n",
       "      <td>growth</td>\n",
       "      <td>pattern</td>\n",
       "      <td>problem</td>\n",
       "      <td>phone</td>\n",
       "      <td>teacher</td>\n",
       "      <td>climate</td>\n",
       "      <td>pay</td>\n",
       "      <td>...</td>\n",
       "      <td>love</td>\n",
       "      <td>sleep</td>\n",
       "      <td>answer</td>\n",
       "      <td>light</td>\n",
       "      <td>coral</td>\n",
       "      <td>place</td>\n",
       "      <td>light</td>\n",
       "      <td>democracy</td>\n",
       "      <td>life</td>\n",
       "      <td>child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>soldier</td>\n",
       "      <td>gender</td>\n",
       "      <td>drug</td>\n",
       "      <td>time</td>\n",
       "      <td>work</td>\n",
       "      <td>good</td>\n",
       "      <td>online</td>\n",
       "      <td>education</td>\n",
       "      <td>fuel</td>\n",
       "      <td>buy</td>\n",
       "      <td>...</td>\n",
       "      <td>happy</td>\n",
       "      <td>cell</td>\n",
       "      <td>problem</td>\n",
       "      <td>life</td>\n",
       "      <td>animal</td>\n",
       "      <td>space</td>\n",
       "      <td>artist</td>\n",
       "      <td>people</td>\n",
       "      <td>human</td>\n",
       "      <td>poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weapon</td>\n",
       "      <td>female</td>\n",
       "      <td>care</td>\n",
       "      <td>economic</td>\n",
       "      <td>understand</td>\n",
       "      <td>create</td>\n",
       "      <td>technology</td>\n",
       "      <td>learn</td>\n",
       "      <td>power</td>\n",
       "      <td>product</td>\n",
       "      <td>...</td>\n",
       "      <td>happiness</td>\n",
       "      <td>body</td>\n",
       "      <td>find</td>\n",
       "      <td>time</td>\n",
       "      <td>shark</td>\n",
       "      <td>people</td>\n",
       "      <td>project</td>\n",
       "      <td>citizen</td>\n",
       "      <td>genetic</td>\n",
       "      <td>community</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>gay</td>\n",
       "      <td>medical</td>\n",
       "      <td>economy</td>\n",
       "      <td>thing</td>\n",
       "      <td>life</td>\n",
       "      <td>open</td>\n",
       "      <td>teach</td>\n",
       "      <td>gas</td>\n",
       "      <td>create</td>\n",
       "      <td>...</td>\n",
       "      <td>emotion</td>\n",
       "      <td>mind</td>\n",
       "      <td>scientist</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>boat</td>\n",
       "      <td>live</td>\n",
       "      <td>picture</td>\n",
       "      <td>public</td>\n",
       "      <td>molecule</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>attack</td>\n",
       "      <td>talk</td>\n",
       "      <td>treatment</td>\n",
       "      <td>global</td>\n",
       "      <td>simple</td>\n",
       "      <td>thing</td>\n",
       "      <td>find</td>\n",
       "      <td>class</td>\n",
       "      <td>solar</td>\n",
       "      <td>cost</td>\n",
       "      <td>...</td>\n",
       "      <td>mind</td>\n",
       "      <td>control</td>\n",
       "      <td>wrong</td>\n",
       "      <td>particle</td>\n",
       "      <td>ice</td>\n",
       "      <td>community</td>\n",
       "      <td>color</td>\n",
       "      <td>change</td>\n",
       "      <td>genome</td>\n",
       "      <td>village</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>peace</td>\n",
       "      <td>young</td>\n",
       "      <td>hospital</td>\n",
       "      <td>future</td>\n",
       "      <td>shape</td>\n",
       "      <td>team</td>\n",
       "      <td>web</td>\n",
       "      <td>high</td>\n",
       "      <td>material</td>\n",
       "      <td>sell</td>\n",
       "      <td>...</td>\n",
       "      <td>feeling</td>\n",
       "      <td>child</td>\n",
       "      <td>datum</td>\n",
       "      <td>energy</td>\n",
       "      <td>whale</td>\n",
       "      <td>street</td>\n",
       "      <td>photograph</td>\n",
       "      <td>vote</td>\n",
       "      <td>bacteria</td>\n",
       "      <td>poverty</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0       1          2         3           4        5            6  \\\n",
       "0          war   woman    patient   country        kind     work        datum   \n",
       "1         kill     man     cancer     world   structure     time  information   \n",
       "2     conflict    girl    disease    change        form   people     internet   \n",
       "3      refugee     sex     health     China      system   change       people   \n",
       "4     military     boy     doctor    growth     pattern  problem        phone   \n",
       "5      soldier  gender       drug      time        work     good       online   \n",
       "6       weapon  female       care  economic  understand   create   technology   \n",
       "7  Afghanistan     gay    medical   economy       thing     life         open   \n",
       "8       attack    talk  treatment    global      simple    thing         find   \n",
       "9        peace   young   hospital    future       shape     team          web   \n",
       "\n",
       "           7         8         9  ...          25             26         27  \\\n",
       "0     school     water     money  ...        feel          brain    science   \n",
       "1        kid    energy   company  ...      people         neuron     people   \n",
       "2    student       oil  business  ...  experience         memory   question   \n",
       "3      child    carbon    market  ...        life  consciousness      study   \n",
       "4    teacher   climate       pay  ...        love          sleep     answer   \n",
       "5  education      fuel       buy  ...       happy           cell    problem   \n",
       "6      learn     power   product  ...   happiness           body       find   \n",
       "7      teach       gas    create  ...     emotion           mind  scientist   \n",
       "8      class     solar      cost  ...        mind        control      wrong   \n",
       "9       high  material      sell  ...     feeling          child      datum   \n",
       "\n",
       "         28      29         30          31          32        33         34  \n",
       "0    planet   ocean       city         art  government      cell      world  \n",
       "1  universe    fish   building       image     country       dna     people  \n",
       "2     space   water     design        work       power      gene    country  \n",
       "3      star     sea      build      create   political      body      India  \n",
       "4     light   coral      place       light   democracy      life      child  \n",
       "5      life  animal      space      artist      people     human       poor  \n",
       "6      time   shark     people     project     citizen   genetic  community  \n",
       "7    galaxy    boat       live     picture      public  molecule       live  \n",
       "8  particle     ice  community       color      change    genome    village  \n",
       "9    energy   whale     street  photograph        vote  bacteria    poverty  \n",
       "\n",
       "[10 rows x 35 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "topicWords = topicWordsMatrix.applymap(lambda x:ast.literal_eval(x)[1])\n",
    "topicWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T06:23:07.719558Z",
     "start_time": "2020-07-29T06:17:57.807801Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['war', 'kill', 'conflict', 'refugee', 'military', 'soldier', 'weapon', 'Afghanistan', 'attack', 'peace']\n",
      "['woman', 'man', 'girl', 'sex', 'boy', 'gender', 'female', 'gay', 'talk', 'young']\n",
      "['patient', 'cancer', 'disease', 'health', 'doctor', 'drug', 'care', 'medical', 'treatment', 'hospital']\n",
      "['country', 'world', 'change', 'China', 'growth', 'time', 'economic', 'economy', 'global', 'future']\n",
      "['kind', 'structure', 'form', 'system', 'pattern', 'work', 'understand', 'thing', 'simple', 'shape']\n",
      "['work', 'time', 'people', 'change', 'problem', 'good', 'create', 'life', 'thing', 'team']\n",
      "['datum', 'information', 'internet', 'people', 'phone', 'online', 'technology', 'open', 'find', 'web']\n",
      "['school', 'kid', 'student', 'child', 'teacher', 'education', 'learn', 'teach', 'class', 'high']\n",
      "['water', 'energy', 'oil', 'carbon', 'climate', 'fuel', 'power', 'gas', 'solar', 'material']\n",
      "['money', 'company', 'business', 'market', 'pay', 'buy', 'product', 'create', 'cost', 'sell']\n",
      "['human', 'animal', 'specie', 'evolution', 'find', 'male', 'dog', 'evolve', 'creature', 'monkey']\n",
      "['people', 'world', 'human', 'social', 'idea', 'society', 'thing', 'culture', 'kind', 'question']\n",
      "['story', 'world', 'god', 'life', 'man', 'great', 'live', 'love', 'call', 'human']\n",
      "['people', 'black', 'police', 'law', 'prison', 'violence', 'crime', 'man', 'community', 'white']\n",
      "['music', 'sound', 'play', 'hear', 'song', 'listen', 'voice', 'instrument', 'piece', 'sing']\n",
      "['life', 'family', 'child', 'time', 'mother', 'home', 'story', 'love', 'friend', 'live']\n",
      "['tree', 'forest', 'find', 'specie', 'river', 'land', 'world', 'mountain', 'dinosaur', 'place']\n",
      "['body', 'hand', 'leg', 'walk', 'time', 'foot', 'head', 'arm', 'feel', 'run']\n",
      "['food', 'plant', 'eat', 'grow', 'farmer', 'bee', 'feed', 'farm', 'flower', 'crop']\n",
      "['car', 'fly', 'drive', 'road', 'vehicle', 'ant', 'airplane', 'flight', 'driver', 'light']\n",
      "['thing', 'people', 'lot', 'kind', 'time', 'talk', 'work', 'start', 'happen', 'good']\n",
      "['game', 'play', 'good', 'yeah', 'player', 'win', 'number', 'card', 'video', 'da']\n",
      "['technology', 'computer', 'machine', 'design', 'robot', 'human', 'build', 'world', 'create', 'video']\n",
      "['book', 'word', 'language', 'write', 'read', 'letter', 'speak', 'sentence', 'page', 'poem']\n",
      "['film', 'movie', 'story', 'character', 'book', 'medium', 'tv', 'play', 'guy', 'cartoon']\n",
      "['feel', 'people', 'experience', 'life', 'love', 'happy', 'happiness', 'emotion', 'mind', 'feeling']\n",
      "['brain', 'neuron', 'memory', 'consciousness', 'sleep', 'cell', 'body', 'mind', 'control', 'child']\n",
      "['science', 'people', 'question', 'study', 'answer', 'problem', 'find', 'scientist', 'wrong', 'datum']\n",
      "['planet', 'universe', 'space', 'star', 'light', 'life', 'time', 'galaxy', 'particle', 'energy']\n",
      "['ocean', 'fish', 'water', 'sea', 'coral', 'animal', 'shark', 'boat', 'ice', 'whale']\n",
      "['city', 'building', 'design', 'build', 'place', 'space', 'people', 'live', 'community', 'street']\n",
      "['art', 'image', 'work', 'create', 'light', 'artist', 'project', 'picture', 'color', 'photograph']\n",
      "['government', 'country', 'power', 'political', 'democracy', 'people', 'citizen', 'public', 'change', 'vote']\n",
      "['cell', 'dna', 'gene', 'body', 'life', 'human', 'genetic', 'molecule', 'genome', 'bacteria']\n",
      "['world', 'people', 'country', 'India', 'child', 'poor', 'community', 'live', 'village', 'poverty']\n"
     ]
    }
   ],
   "source": [
    "topic_concepts = {}\n",
    "for i in range(35):\n",
    "    topic_keywords = topicWords.iloc[:,i].tolist()\n",
    "    print(topic_keywords)\n",
    "    concept = generate_topic(topic_keywords)\n",
    "    topic_concepts[i] = concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T06:27:54.886334Z",
     "start_time": "2020-07-29T06:27:54.873286Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(topic_concepts,open('data/pickle/topic_concepts.p','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
